# PhiÃªn báº£n Fast Conformer

> **Nháº­n dáº¡ng giá»ng nÃ³i streaming chá»‰ vá»›i ~300 dÃ²ng mÃ£.**

Kho lÆ°u trá»¯ nÃ y cung cáº¥p má»™t pipeline huáº¥n luyá»‡n vÃ  suy luáº­n ASR (Automatic Speech Recognition) gá»n nháº¹ nhÆ°ng sáºµn sÃ ng cho sáº£n xuáº¥t, xÃ¢y dá»±ng trÃªn **PyTorch Lightning** vÃ  **torchaudio â‰¥ 2.2**.  
MÃ´ hÃ¬nh sá»­ dá»¥ng **Fast Conformer encoder** (Ä‘Ã£ loáº¡i bá» má»i biáº¿n thá»ƒ Conformer cÅ©) vÃ  má»¥c tiÃªu huáº¥n luyá»‡n káº¿t há»£p **CTC + RNNT** vá»›i tÃ¹y chá»n CTC phá»¥ cho cÃ¡c táº§ng trung gian.

## âœ¨ Äiá»ƒm ná»•i báº­t

â€¢ **Chá»‰ Fast Conformer** â€“ thÃ¢n thiá»‡n streaming, tuá»³ chá»‰nh ngá»¯ cáº£nh trÃ¡i/pháº£i.  
â€¢ **Loss** â€“ CTC, RNNT vÃ  CTC trung gian giÃºp há»™i tá»¥ nhanh hÆ¡n.  
â€¢ **Checkpoint theo bÆ°á»›c** â€“ lÆ°u checkpoint **WER tá»‘t nháº¥t** + checkpoint FP16 (chá»‰ weights) Ä‘á»‹nh ká»³ (~200 MB).  
â€¢ **Äiá»u khiá»ƒn báº±ng config** â€“ má»i siÃªu tham sá»‘ náº±m trong `config.py` / `config.json`.  
â€¢ **Suy luáº­n streaming** vá»›i cá»­a sá»• 640 ms, chá»“ng láº¥n 160 ms.  
â€¢ **Phá»¥ thuá»™c tá»‘i thiá»ƒu** â€“ thuáº§n PyTorch, khÃ´ng cáº§n Fairseq/SentencePiece.

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```text
â”œâ”€â”€ config.py               # Dataclass chá»©a máº·c Ä‘á»‹nh
â”œâ”€â”€ config.json             # VÃ­ dá»¥ config (ghi Ä‘Ã¨ máº·c Ä‘á»‹nh)
â”œâ”€â”€ rnnt_lightning.py       # LightningModule cho huáº¥n luyá»‡n RNN-T only
â”œâ”€â”€ run.py                  # Äiá»ƒm vÃ o huáº¥n luyá»‡n (argparse + Lightning Trainer)
â”œâ”€â”€ inference.py            # Suy luáº­n offline
â”œâ”€â”€ streaming_inference.py  # Demo suy luáº­n thá»i gian thá»±c
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fast_conformer.py   # Fast Conformer encoder (torchaudio â‰¥ 2.2)
â”‚   â”œâ”€â”€ rnnt_decoder.py     # RNN-T decoder vá»›i LSTMCell (Lightning compatible)
â”‚   â””â”€â”€ rnnt_streaming.py   # Streaming RNN-T decoder cho real-time inference
â””â”€â”€ utils/                  # Táº£i dá»¯ liá»‡u, augmentation, metrics, ...
```

---

## âš¡ Báº¯t Ä‘áº§u nhanh

1. **CÃ i Ä‘áº·t phá»¥ thuá»™c** (khuyÃªn dÃ¹ng Python â‰¥ 3.9):

   ```bash
   python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
   pip install --upgrade pip
   pip install -r requirements.txt
   # torchaudio pháº£i khá»›p phiÃªn báº£n CUDA/CPU cá»§a PyTorch.
   ```

2. **Chuáº©n bá»‹ dá»¯ liá»‡u**: táº¡o file `metadata.csv` theo Ä‘á»‹nh dáº¡ng

   ```text
   /duong_dan/tuyet_doi/audio_0001.wav|xin chÃ o tháº¿ giá»›i
   /duong_dan/tuyet_doi/audio_0002.wav|general kenobi
   ```

   Cáº­p nháº­t láº¡i Ä‘Æ°á»ng dáº«n trong `config.json â†’ data` cho phÃ¹ há»£p.

3. **Huáº¥n luyá»‡n**:

   ```bash
   python run.py --config config.json
   ```

4. **Validation Prediction** (tÃ¹y chá»n):

   Trong quÃ¡ trÃ¬nh training, model sáº½ tá»± Ä‘á»™ng predict:
   - 5 samples ngáº«u nhiÃªn tá»« validation set
   - Táº¥t cáº£ file audio trong thÆ° má»¥c tÃ¹y chá»‰nh (náº¿u cÃ³)

   ```bash
   # Chá»‰ Ä‘á»‹nh thÆ° má»¥c Ä‘á»ƒ predict thÃªm
   python run.py --config config.json --val-predict-dir ./test_audio

   # TÃ¹y chá»‰nh sá»‘ lÆ°á»£ng random samples
   python run.py --config config.json --val-predict-samples 10
   ```

   Má»™t sá»‘ tuá»³ chá»n ghi Ä‘Ã¨ nhanh:

   ```bash
   python run.py --config config.json --batch-size 16 --learning-rate 2e-4
   # Tiáº¿p tá»¥c tá»« checkpoint
   python run.py --config config.json --resume checkpoints/last.ckpt
   ```

4. **Suy luáº­n offline**:

   ```bash
   python inference.py --wav test.wav --checkpoint checkpoints/best-wer.ckpt
   ```

5. **Suy luáº­n streaming** (Ä‘á»™ trá»… tháº¥p):

   ```bash
   python streaming_inference.py \
       --wav test.wav \
       --checkpoint weights/encoder_ctc.pt \
       --left-ctx 160 --right-ctx 40
   ```

---

## ğŸ› ï¸ Báº£ng tham chiáº¿u cáº¥u hÃ¬nh (`config.py` / `config.json`)

| NhÃ³m         | KhoÃ¡                          | Ã nghÄ©a                                            |
|--------------|------------------------------|----------------------------------------------------|
| `model`      | `n_state` / `n_head` / `n_layer` | Chiá»u vÃ  Ä‘á»™ sÃ¢u Transformer                       |
|              | `left_ctx` / `right_ctx`     | Ngá»¯ cáº£nh streaming (frame)                         |
|              | `dropout` / `ffn_expansion`  | Regularization & scale FFN                         |
| `training`   | `batch_size` / `learning_rate` | Tham sá»‘ tá»‘i Æ°u hoÃ¡                                |
|              | `checkpoint_every_n_steps`   | Khoáº£ng lÆ°u checkpoint FP16 (chá»‰ weights)           |
|              | `val_check_interval`         | Táº§n suáº¥t validate (tÃ­nh theo step)                 |
| `loss`       | `lambda_ctc` / `aux_loss_weight` | Tá»· lá»‡ pha trá»™n RNNTâ€“CTC & CTC trung gian        |
| `paths`      | `data_dir` / `log_dir` / `checkpoint_dir` | ThÆ° má»¥c dá»¯ liá»‡u, log, checkpoint      |

Má»i trÆ°á»ng Ä‘Ã£ cÃ³ giÃ¡ trá»‹ máº·c Ä‘á»‹nh trong `config.py`; `config.json` chá»‰ cáº§n ghi Ä‘Ã¨ khi báº¡n muá»‘n thay Ä‘á»•i.

---

## ğŸ“ LÆ°u Ã½ huáº¥n luyá»‡n

1. **Pháº§n cá»©ng** â€“ thá»­ nghiá»‡m trÃªn 1 GPU NVIDIA (â‰¥ 12 GB).  
2. **Mixed precision** â€“ báº­t sáºµn (`precision=16-mixed`).  
3. **Gradient accumulation** â€“ dÃ¹ng `training.accumulate_grad_batches` Ä‘á»ƒ nhá»“i batch lá»›n.  
4. **Augmentation** â€“ `utils/dataset.py` há»— trá»£ SpecAugment, time-stretch, trá»™n nhiá»…u; táº¯t báº±ng `augment=False`.

---

## ğŸ¤ Cáº£m Æ¡n

Dá»± Ã¡n tham kháº£o vÃ  tÃ¡i sá»­ dá»¥ng Ã½ tÆ°á»Ÿng tá»«:  
â€¢ [NVIDIA NeMo](https://github.com/NVIDIA/NeMo) â€“ Fast Conformer & RNNT loss  
â€¢ [torchaudio](https://github.com/pytorch/audio) â€“ Lá»›p encoder & `RNNTLoss`  
â€¢ [OpenAI Whisper](https://github.com/openai/whisper) â€“ Tokeniser & máº¹o decoding

---

## ğŸ“„ Giáº¥y phÃ©p

PhÃ¡t hÃ nh theo giáº¥y phÃ©p **Apache 2.0** â€“ chi tiáº¿t xem file `LICENSE`.
